{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registro del modelo base de Hugging Face en MLflow\n",
    "Esta secci√≥n descarga el modelo base de Hugging Face y lo registra en MLflow como 'image-to-text-base'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n\n",
    "MODEL_NAME = 'nlpconnect/vit-gpt2-image-captioning'\n",
    "MLFLOW_MODEL_NAME = 'image-to-text-base'\n",
    "mlflow.set_tracking_uri('http://localhost:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando modelo base de Hugging Face...\n",
      "Modelo base descargado.\n"
     ]
    }
   ],
   "source": [
    "# Descargar modelo base\n",
    "print('Descargando modelo base de Hugging Face...')\n",
    "model = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME)\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print('Modelo base descargado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registrando modelo base en MLflow como image-to-text-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/05 11:16:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'image-to-text-base'.\n",
      "2025/07/05 11:16:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: image-to-text-base, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo base registrado en MLflow.\n",
      "Tokenizer y feature extractor guardados.\n",
      "üèÉ View run register-base-model at: http://localhost:5000/#/experiments/0/runs/239736e6fd9d4a61809a613071c5747d\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'image-to-text-base'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Registrar en MLflow\n",
    "with mlflow.start_run(run_name='register-base-model') as run:\n",
    "    print(f'Registrando modelo base en MLflow como {MLFLOW_MODEL_NAME}...')\n",
    "    mlflow.log_param('huggingface_model', MODEL_NAME)\n",
    "    mlflow.pytorch.log_model(model, 'model', registered_model_name=MLFLOW_MODEL_NAME)\n",
    "    print('Modelo base registrado en MLflow.')\n",
    "    # Guardar tokenizer y feature extractor localmente\n",
    "    tokenizer.save_pretrained('./results/tokenizer_base')\n",
    "    feature_extractor.save_pretrained('./results/feature_extractor_base')\n",
    "    print('Tokenizer y feature extractor guardados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el modelo base desde MLflow para fine-tuning\n",
    "Esta celda carga el modelo base registrado en MLflow para usarlo como punto de partida en el fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ViTImageProcessor, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo base desde MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:29<00:00,  4.88s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo base cargado desde MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Nombre del modelo registrado en MLflow\n",
    "MLFLOW_MODEL_NAME = 'image-to-text-base'\n",
    "\n",
    "# Cargar modelo desde MLflow\n",
    "print('Cargando modelo base desde MLflow...')\n",
    "model = mlflow.pytorch.load_model(f'models:/{MLFLOW_MODEL_NAME}/latest')\n",
    "print('Modelo base cargado desde MLflow.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer y feature extractor cargados.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar tokenizer y feature extractor locales (guardados previamente)\n",
    "tokenizer = AutoTokenizer.from_pretrained('./results/tokenizer_base')\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('./results/feature_extractor_base')\n",
    "print('Tokenizer y feature extractor cargados.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
